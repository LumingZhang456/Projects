{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reporting: wragle_report\n",
    "* Create a **300-600 word written report** called \"wrangle_report.pdf\" or \"wrangle_report.html\" that briefly describes your wrangling efforts. This is to be framed as an internal document."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is the tweet archive of Twitter user [@dog_rate](https://twitter.com/dog_rates), also known as [WeRateDogs](https://en.wikipedia.org/wiki/WeRateDogs). WeRateDogs is a Twitter account that rates people's dogs with a humorous comment about the dog. \n",
    "\n",
    "The project intends to analyze the dataset by doing data wrangling and data visualization to get some insights.\n",
    "\n",
    "The project will concluding 5 parts:\n",
    "1. Data Gathering\n",
    "2. Assessing Data\n",
    "3. Cleaning Data\n",
    "4. Storing Data\n",
    "5. Analyzing and Visualizing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Gathering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (1) twitter_archive_enhanced.csv\n",
    "\n",
    "Directly download the WeRateDogs Twitter archive data ([twitter_archive_enhanced.csv](https://d17h27t6h515a5.cloudfront.net/topher/2017/August/59a4e958_twitter-archive-enhanced/twitter-archive-enhanced.csv))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (2) image_predictions.tsv\n",
    "\n",
    "The tweet image predictions, i.e., what breed of dog (or other object, animal, etc.) is present in each tweet according to a neural network.\n",
    "\n",
    "This dataset can be downloaded programmatically using the [Requests](https://pypi.org/project/requests/) library and the following URL: https://d17h27t6h515a5.cloudfront.net/topher/2017/August/599fd2ad_image-predictions/image-predictions.tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (3) Twitter API & JSON\n",
    "\n",
    "Using the tweet IDs in the WeRateDogs Twitter archive, query the Twitter API for each tweet's JSON data using Python's Tweepy library and store each tweet's entire set of JSON data in a file called tweet_json.txt file. Then read this .txt file line by line into a pandas DataFrame with (at minimum) tweet ID, retweet count, and favorite count."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assessing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After gathering each of the above pieces of data,I checked datatype, null values and duplicated values for each dataset. And here are quality issues and tidiness issues that I found during the process:\n",
    "\n",
    "##### Quality issues\n",
    "1. Dropping irrelavent columns from those datasets for our analysis.\n",
    "\n",
    "2. For archive table, there are missing values in columns __in_reply_to_status_id, in_reply_to_user_id, retweeted_status_id, retweeted_status_user_id, retweeted_status_timestamp, and expanded_urls.__\n",
    "\n",
    "3. For tweet table, the column name __id_str__ should be change to __tweet_id__.\n",
    "\n",
    "4. For archive table, columns __timestamp__ and __retweeted_status_timestamp__ have incorrect data type.\n",
    "\n",
    "5. For tweet image table, the total number of data is 2075 instead of 2356.\n",
    "\n",
    "6. For archive table, column __tweet_id__ has incorrect data type.\n",
    "\n",
    "7. For tweeet image table, column __tweet_id__ has incorrect data type.\n",
    "\n",
    "8. For tweet table, the total number of data is 2354 instead of 2356.\n",
    "\n",
    "9. For tweet image table, the first letter of each name of columns __p1, p2__ and __p3__ are mixed with uppercases and lowercases. \n",
    "\n",
    "##### Tidiness issues\n",
    "1. Create a new column called rating, which equals to __rating_numerator / rating_denominator__.\n",
    "\n",
    "2. Those three tables should be merged to one table. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This part will be used to clean each of issues that I documented while assessing. For each issues, there are three parts of it: define, code and test. \n",
    "\n",
    "First of all, I made a copy of the original data before cleaning. Then, I removed retweets by selecting only rows that have null values in retweet related columns, using pandas isnull() function. Moreover, to make analysis much eaiser, I dropped the irrelavent columns for our analysis using function 'drop()'. After that, I used function 'dropna()\" to deal with missing values. For the incorrect column name and data type, I used function 'rename()', 'to_datetime()' and 'astype(str)' to make correction. For mixed uppercases and lowercases, I used 'str.lower()' to converting all names into lowercases. At the end of this part, I merged those tables into one table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Storing Data\n",
    "\n",
    "I saved gathered, assessed, and cleaned master dataset to a CSV file named \"twitter_archive_master.csv\" using function 'to_csv()\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
